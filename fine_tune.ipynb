{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning Gemma 2 2b for Resume Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting JSON to JSONL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 153 records to resume_parser_instruct.jsonl in instruct format.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Let's assume your original data is in a file \"resume_data.json\"\n",
    "# which looks like: [{\"Filename\": \"...\", \"Question\": \"...\", \"Answer\": {...}}, ...]\n",
    "\n",
    "INPUT_FILE = \"output.json\"\n",
    "OUTPUT_FILE = \"resume_parser_instruct.jsonl\"\n",
    "\n",
    "# The generic instruction\n",
    "BASE_INSTRUCTION = (\n",
    "    '''You are a helpful assistant that extracts structured data from the given resume text.\n",
    "\n",
    "Important Instructions:\n",
    "1. Output Format: Return only a single JSON object that strictly follows the requested structure.\n",
    "2. No Extra Text: Do not include any additional text, explanations, code fences, triple backticks, or any formatting beyond the JSON object.\n",
    "3. No Missing Keys: Include all keys listed below, even if their values are empty or blank.\n",
    "4. No Trailing Commas: Ensure that there are no trailing commas after the last item in arrays or objects.\n",
    "5. Data Structure:\n",
    "   - name: string\n",
    "   - location: string\n",
    "   - email: string\n",
    "   - phone: string\n",
    "   - linkedin: string\n",
    "   - skills: an array of strings\n",
    "   - experience: an array of objects, each with keys \"role\", \"company\", \"location\", \"start_date\", \"end_date\", \"description\"\n",
    "   - projects: an array of objects, each with keys \"title\", \"start_date\", \"end_date\", \"description\", \"tech_stack\" (where \"tech_stack\" is an array of strings)\n",
    "   - education: an array of objects, each with keys \"degree\", \"institution\", \"start_date\", \"end_date\", \"gpa\"\n",
    "   - extracurricular_activities: an array of objects, each with keys \"activity\" and \"description\"\n",
    "6. Strictly follow the structure in step 5. Do not create new keys by yourself. Use only the keys I mentioned in step 5. \n",
    "7. You are part of a resume parsing pipeline so it's really important you return a json only object and again. Strictly follow the key names in step 5. \n",
    "If a field is not found in the resume, return an empty string \"\" for strings or an empty array [] for lists.'''\n",
    "\n",
    ")\n",
    "\n",
    "def convert_to_instruct_format(original_item):\n",
    "    \"\"\"\n",
    "    original_item is a dict with keys: ['Filename', 'Question', 'Answer']\n",
    "    We'll build a new dict: {'instruction': ..., 'input': ..., 'output': ...}\n",
    "    \"\"\"\n",
    "    # 1. Build the instruction\n",
    "    instruction = BASE_INSTRUCTION\n",
    "\n",
    "    # 2. The input is the resume text from the \"Question\" field\n",
    "    input_text = original_item.get(\"Question\", \"\")\n",
    "\n",
    "    # 3. Convert the 'Answer' dictionary to a JSON string\n",
    "    #    so we can store it in \"output\" as text.\n",
    "    answer_dict = original_item.get(\"Answer\", {})\n",
    "    # Dump to a single-line JSON string\n",
    "    output_text = json.dumps(answer_dict, ensure_ascii=False)\n",
    "\n",
    "    # Construct the final record\n",
    "    new_item = {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": input_text,\n",
    "        \"output\": output_text\n",
    "    }\n",
    "    return new_item\n",
    "\n",
    "def main():\n",
    "    # 1. Read original data\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as infile:\n",
    "        data = json.load(infile)  # data should be a list of dicts\n",
    "\n",
    "    # 2. Transform each item\n",
    "    transformed_data = []\n",
    "    for item in data:\n",
    "        transformed_item = convert_to_instruct_format(item)\n",
    "        transformed_data.append(transformed_item)\n",
    "\n",
    "    # 3. Write new data to JSONL\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for td in transformed_data:\n",
    "            # Dump each record as a single line in JSON\n",
    "            json_line = json.dumps(td, ensure_ascii=False)\n",
    "            outfile.write(json_line + \"\\n\")\n",
    "\n",
    "    print(f\"Converted {len(transformed_data)} records to {OUTPUT_FILE} in instruct format.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
